{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense,Dropout,Activation  \n",
    "from keras.layers import Embedding \n",
    "from keras.layers import LSTM  \n",
    "from keras.datasets import imdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seq:25000\n",
      "Test seq:25000\n",
      "Train example:\n",
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "nTest example:\n",
      ":[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
     ]
    }
   ],
   "source": [
    "n_words = 1000\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=n_words)\n",
    "print('Train seq:{}'.format(len(X_train)))\n",
    "print('Test seq:{}'.format(len(X_train)))\n",
    "print('Train example:\\n{}'.format(X_train[0]))\n",
    "print('nTest example:\\n:{}'.format(X_test[0]))\n",
    "max_len = 200\n",
    "\n",
    "X_train = tf.keras.utils.pad_sequences(X_train,maxlen=max_len)\n",
    "X_test =tf.keras.utils.pad_sequences(X_test,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 50)           50000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 50)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               60400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               25250     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,901\n",
      "Trainable params: 135,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 559s 1s/step - loss: 0.4942 - accuracy: 0.7521\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 585s 1s/step - loss: 0.3677 - accuracy: 0.8436\n",
      "Epoch 3/10\n",
      "373/391 [===========================>..] - ETA: 30s - loss: 0.3514 - accuracy: 0.8514"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Embedding(n_words,50,input_length=max_len),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100,dropout=0.2,recurrent_dropout=0.2),\n",
    "    Dense(250,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train,y_train,batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Accuracy on test set:{}'.format(model.evaluate(X_test,y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
