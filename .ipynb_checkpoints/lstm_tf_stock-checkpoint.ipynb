{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T05:40:08.784235Z",
     "iopub.status.busy": "2023-05-16T05:40:08.783739Z",
     "iopub.status.idle": "2023-05-16T05:40:08.791085Z",
     "shell.execute_reply": "2023-05-16T05:40:08.789996Z",
     "shell.execute_reply.started": "2023-05-16T05:40:08.784191Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np   \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers.core import Dense,Activation,Dropout\n",
    "from keras.layers import LSTM \n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T05:40:10.768344Z",
     "iopub.status.busy": "2023-05-16T05:40:10.767823Z",
     "iopub.status.idle": "2023-05-16T05:40:10.791459Z",
     "shell.execute_reply": "2023-05-16T05:40:10.790217Z",
     "shell.execute_reply.started": "2023-05-16T05:40:10.768315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11727.139648</td>\n",
       "      <td>11804.589844</td>\n",
       "      <td>11627.530273</td>\n",
       "      <td>4930250000</td>\n",
       "      <td>11662.790039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11905.570313</td>\n",
       "      <td>11988.429688</td>\n",
       "      <td>11754.280273</td>\n",
       "      <td>5093960000</td>\n",
       "      <td>11984.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11790.679688</td>\n",
       "      <td>11826.219727</td>\n",
       "      <td>11381.690430</td>\n",
       "      <td>5064120000</td>\n",
       "      <td>11418.150391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11364.400391</td>\n",
       "      <td>11562.820313</td>\n",
       "      <td>11313.309570</td>\n",
       "      <td>5154410000</td>\n",
       "      <td>11388.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11542.669922</td>\n",
       "      <td>11552.209961</td>\n",
       "      <td>11035.690430</td>\n",
       "      <td>5434370000</td>\n",
       "      <td>11354.620117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low      Volume         Close\n",
       "0  11727.139648  11804.589844  11627.530273  4930250000  11662.790039\n",
       "1  11905.570313  11988.429688  11754.280273  5093960000  11984.519531\n",
       "2  11790.679688  11826.219727  11381.690430  5064120000  11418.150391\n",
       "3  11364.400391  11562.820313  11313.309570  5154410000  11388.500000\n",
       "4  11542.669922  11552.209961  11035.690430  5434370000  11354.620117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('stock.csv')\n",
    "data = data[['Open','High','Low','Volume','Close']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T05:40:14.863249Z",
     "iopub.status.busy": "2023-05-16T05:40:14.862794Z",
     "iopub.status.idle": "2023-05-16T05:40:14.873612Z",
     "shell.execute_reply": "2023-05-16T05:40:14.872407Z",
     "shell.execute_reply.started": "2023-05-16T05:40:14.863213Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 21\n",
    "n_features = len(data.columns)\n",
    "val_ratio = 0.1\n",
    "n_epochs = 300\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T05:41:32.394135Z",
     "iopub.status.busy": "2023-05-16T05:41:32.393632Z",
     "iopub.status.idle": "2023-05-16T05:41:32.407468Z",
     "shell.execute_reply": "2023-05-16T05:41:32.406269Z",
     "shell.execute_reply.started": "2023-05-16T05:41:32.394087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:,:].values\n",
    "data_processed = []\n",
    "for index in range(len(data)-sequence_length):\n",
    "    data_processed.append(data[index:index+sequence_length])\n",
    "data_processed = np.array(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T05:41:35.933211Z",
     "iopub.status.busy": "2023-05-16T05:41:35.932227Z",
     "iopub.status.idle": "2023-05-16T05:41:35.941395Z",
     "shell.execute_reply": "2023-05-16T05:41:35.940263Z",
     "shell.execute_reply.started": "2023-05-16T05:41:35.933160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:(207, 21, 5)\n",
      "vali data:(23, 21, 5)\n"
     ]
    }
   ],
   "source": [
    "val_split  = round((1-val_ratio)*data_processed.shape[0])\n",
    "train = data_processed[:int(val_split),:]\n",
    "val = data_processed[int(val_split):,:]\n",
    "print('Training data:{}'.format(train.shape))\n",
    "print('vali data:{}'.format(val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T05:41:38.648177Z",
     "iopub.status.busy": "2023-05-16T05:41:38.647560Z",
     "iopub.status.idle": "2023-05-16T05:41:38.659452Z",
     "shell.execute_reply": "2023-05-16T05:41:38.658035Z",
     "shell.execute_reply.started": "2023-05-16T05:41:38.648130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_samples, train_nx, train_ny = train.shape\n",
    "val_samples, val_nx, val_ny = val.shape\n",
    "\n",
    "train = train.reshape((train_samples, train_nx * train_ny))\n",
    "val = val.reshape((val_samples, val_nx * val_ny))\n",
    "\n",
    "preprocessor = MinMaxScaler().fit(train)\n",
    "train = preprocessor.transform(train)\n",
    "val = preprocessor.transform(val)\n",
    "\n",
    "train = train.reshape((train_samples, train_nx, train_ny))\n",
    "val = val.reshape((val_samples, val_nx, val_ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T05:41:41.480080Z",
     "iopub.status.busy": "2023-05-16T05:41:41.479552Z",
     "iopub.status.idle": "2023-05-16T05:41:41.488312Z",
     "shell.execute_reply": "2023-05-16T05:41:41.487345Z",
     "shell.execute_reply.started": "2023-05-16T05:41:41.480036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train[:, : -1]\n",
    "y_train = train[:, -1][: ,-1]\n",
    "X_val = val[:, : -1]\n",
    "y_val = val[:, -1][ : ,-1]\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T05:42:36.830547Z",
     "iopub.status.busy": "2023-05-16T05:42:36.830028Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 - 6s - loss: 0.2119 - 6s/epoch - 6s/step\n",
      "Epoch 2/300\n",
      "1/1 - 0s - loss: 0.0670 - 137ms/epoch - 137ms/step\n",
      "Epoch 3/300\n",
      "1/1 - 0s - loss: 0.0275 - 135ms/epoch - 135ms/step\n",
      "Epoch 4/300\n",
      "1/1 - 0s - loss: 0.0717 - 115ms/epoch - 115ms/step\n",
      "Epoch 5/300\n",
      "1/1 - 0s - loss: 0.0531 - 120ms/epoch - 120ms/step\n",
      "Epoch 6/300\n",
      "1/1 - 0s - loss: 0.0272 - 113ms/epoch - 113ms/step\n",
      "Epoch 7/300\n",
      "1/1 - 0s - loss: 0.0237 - 140ms/epoch - 140ms/step\n",
      "Epoch 8/300\n",
      "1/1 - 0s - loss: 0.0255 - 131ms/epoch - 131ms/step\n",
      "Epoch 9/300\n",
      "1/1 - 0s - loss: 0.0305 - 112ms/epoch - 112ms/step\n",
      "Epoch 10/300\n",
      "1/1 - 0s - loss: 0.0338 - 113ms/epoch - 113ms/step\n",
      "Epoch 11/300\n",
      "1/1 - 0s - loss: 0.0347 - 122ms/epoch - 122ms/step\n",
      "Epoch 12/300\n",
      "1/1 - 0s - loss: 0.0325 - 137ms/epoch - 137ms/step\n",
      "Epoch 13/300\n",
      "1/1 - 0s - loss: 0.0295 - 117ms/epoch - 117ms/step\n",
      "Epoch 14/300\n",
      "1/1 - 0s - loss: 0.0219 - 116ms/epoch - 116ms/step\n",
      "Epoch 15/300\n",
      "1/1 - 0s - loss: 0.0208 - 121ms/epoch - 121ms/step\n",
      "Epoch 16/300\n",
      "1/1 - 0s - loss: 0.0200 - 136ms/epoch - 136ms/step\n",
      "Epoch 17/300\n",
      "1/1 - 0s - loss: 0.0217 - 150ms/epoch - 150ms/step\n",
      "Epoch 18/300\n",
      "1/1 - 0s - loss: 0.0234 - 113ms/epoch - 113ms/step\n",
      "Epoch 19/300\n",
      "1/1 - 0s - loss: 0.0247 - 113ms/epoch - 113ms/step\n",
      "Epoch 20/300\n",
      "1/1 - 0s - loss: 0.0225 - 126ms/epoch - 126ms/step\n",
      "Epoch 21/300\n",
      "1/1 - 0s - loss: 0.0206 - 126ms/epoch - 126ms/step\n",
      "Epoch 22/300\n",
      "1/1 - 0s - loss: 0.0186 - 125ms/epoch - 125ms/step\n",
      "Epoch 23/300\n",
      "1/1 - 0s - loss: 0.0182 - 118ms/epoch - 118ms/step\n",
      "Epoch 24/300\n",
      "1/1 - 0s - loss: 0.0191 - 114ms/epoch - 114ms/step\n",
      "Epoch 25/300\n",
      "1/1 - 0s - loss: 0.0198 - 111ms/epoch - 111ms/step\n",
      "Epoch 26/300\n",
      "1/1 - 0s - loss: 0.0197 - 147ms/epoch - 147ms/step\n",
      "Epoch 27/300\n",
      "1/1 - 0s - loss: 0.0190 - 161ms/epoch - 161ms/step\n",
      "Epoch 28/300\n",
      "1/1 - 0s - loss: 0.0197 - 138ms/epoch - 138ms/step\n",
      "Epoch 29/300\n",
      "1/1 - 0s - loss: 0.0177 - 133ms/epoch - 133ms/step\n",
      "Epoch 30/300\n",
      "1/1 - 0s - loss: 0.0176 - 153ms/epoch - 153ms/step\n",
      "Epoch 31/300\n",
      "1/1 - 0s - loss: 0.0168 - 151ms/epoch - 151ms/step\n",
      "Epoch 32/300\n",
      "1/1 - 0s - loss: 0.0160 - 163ms/epoch - 163ms/step\n",
      "Epoch 33/300\n",
      "1/1 - 0s - loss: 0.0156 - 127ms/epoch - 127ms/step\n",
      "Epoch 34/300\n",
      "1/1 - 0s - loss: 0.0162 - 117ms/epoch - 117ms/step\n",
      "Epoch 35/300\n",
      "1/1 - 0s - loss: 0.0185 - 172ms/epoch - 172ms/step\n",
      "Epoch 36/300\n",
      "1/1 - 0s - loss: 0.0160 - 138ms/epoch - 138ms/step\n",
      "Epoch 37/300\n",
      "1/1 - 0s - loss: 0.0178 - 130ms/epoch - 130ms/step\n",
      "Epoch 38/300\n",
      "1/1 - 0s - loss: 0.0134 - 116ms/epoch - 116ms/step\n",
      "Epoch 39/300\n",
      "1/1 - 0s - loss: 0.0152 - 137ms/epoch - 137ms/step\n",
      "Epoch 40/300\n",
      "1/1 - 0s - loss: 0.0146 - 132ms/epoch - 132ms/step\n",
      "Epoch 41/300\n",
      "1/1 - 0s - loss: 0.0146 - 123ms/epoch - 123ms/step\n",
      "Epoch 42/300\n",
      "1/1 - 0s - loss: 0.0156 - 121ms/epoch - 121ms/step\n",
      "Epoch 43/300\n",
      "1/1 - 0s - loss: 0.0143 - 111ms/epoch - 111ms/step\n",
      "Epoch 44/300\n",
      "1/1 - 0s - loss: 0.0144 - 125ms/epoch - 125ms/step\n",
      "Epoch 45/300\n",
      "1/1 - 0s - loss: 0.0143 - 134ms/epoch - 134ms/step\n",
      "Epoch 46/300\n",
      "1/1 - 0s - loss: 0.0145 - 114ms/epoch - 114ms/step\n",
      "Epoch 47/300\n",
      "1/1 - 0s - loss: 0.0147 - 133ms/epoch - 133ms/step\n",
      "Epoch 48/300\n",
      "1/1 - 0s - loss: 0.0126 - 137ms/epoch - 137ms/step\n",
      "Epoch 49/300\n",
      "1/1 - 0s - loss: 0.0146 - 125ms/epoch - 125ms/step\n",
      "Epoch 50/300\n",
      "1/1 - 0s - loss: 0.0138 - 122ms/epoch - 122ms/step\n",
      "Epoch 51/300\n",
      "1/1 - 0s - loss: 0.0133 - 119ms/epoch - 119ms/step\n",
      "Epoch 52/300\n",
      "1/1 - 0s - loss: 0.0138 - 136ms/epoch - 136ms/step\n",
      "Epoch 53/300\n",
      "1/1 - 0s - loss: 0.0147 - 116ms/epoch - 116ms/step\n",
      "Epoch 54/300\n",
      "1/1 - 0s - loss: 0.0127 - 150ms/epoch - 150ms/step\n",
      "Epoch 55/300\n",
      "1/1 - 0s - loss: 0.0134 - 126ms/epoch - 126ms/step\n",
      "Epoch 56/300\n",
      "1/1 - 0s - loss: 0.0129 - 120ms/epoch - 120ms/step\n",
      "Epoch 57/300\n",
      "1/1 - 0s - loss: 0.0126 - 121ms/epoch - 121ms/step\n",
      "Epoch 58/300\n",
      "1/1 - 0s - loss: 0.0124 - 124ms/epoch - 124ms/step\n",
      "Epoch 59/300\n",
      "1/1 - 0s - loss: 0.0124 - 127ms/epoch - 127ms/step\n",
      "Epoch 60/300\n",
      "1/1 - 0s - loss: 0.0128 - 121ms/epoch - 121ms/step\n",
      "Epoch 61/300\n",
      "1/1 - 0s - loss: 0.0127 - 113ms/epoch - 113ms/step\n",
      "Epoch 62/300\n",
      "1/1 - 0s - loss: 0.0121 - 107ms/epoch - 107ms/step\n",
      "Epoch 63/300\n",
      "1/1 - 0s - loss: 0.0132 - 128ms/epoch - 128ms/step\n",
      "Epoch 64/300\n",
      "1/1 - 0s - loss: 0.0135 - 128ms/epoch - 128ms/step\n",
      "Epoch 65/300\n",
      "1/1 - 0s - loss: 0.0122 - 117ms/epoch - 117ms/step\n",
      "Epoch 66/300\n",
      "1/1 - 0s - loss: 0.0123 - 114ms/epoch - 114ms/step\n",
      "Epoch 67/300\n",
      "1/1 - 0s - loss: 0.0132 - 134ms/epoch - 134ms/step\n",
      "Epoch 68/300\n",
      "1/1 - 0s - loss: 0.0126 - 170ms/epoch - 170ms/step\n",
      "Epoch 69/300\n",
      "1/1 - 0s - loss: 0.0130 - 140ms/epoch - 140ms/step\n",
      "Epoch 70/300\n",
      "1/1 - 0s - loss: 0.0123 - 128ms/epoch - 128ms/step\n",
      "Epoch 71/300\n",
      "1/1 - 0s - loss: 0.0122 - 137ms/epoch - 137ms/step\n",
      "Epoch 72/300\n",
      "1/1 - 0s - loss: 0.0122 - 142ms/epoch - 142ms/step\n",
      "Epoch 73/300\n",
      "1/1 - 0s - loss: 0.0126 - 143ms/epoch - 143ms/step\n",
      "Epoch 74/300\n",
      "1/1 - 0s - loss: 0.0128 - 148ms/epoch - 148ms/step\n",
      "Epoch 75/300\n",
      "1/1 - 0s - loss: 0.0132 - 137ms/epoch - 137ms/step\n",
      "Epoch 76/300\n",
      "1/1 - 0s - loss: 0.0119 - 130ms/epoch - 130ms/step\n",
      "Epoch 77/300\n",
      "1/1 - 0s - loss: 0.0121 - 134ms/epoch - 134ms/step\n",
      "Epoch 78/300\n",
      "1/1 - 0s - loss: 0.0123 - 132ms/epoch - 132ms/step\n",
      "Epoch 79/300\n",
      "1/1 - 0s - loss: 0.0117 - 122ms/epoch - 122ms/step\n",
      "Epoch 80/300\n",
      "1/1 - 0s - loss: 0.0119 - 123ms/epoch - 123ms/step\n",
      "Epoch 81/300\n",
      "1/1 - 0s - loss: 0.0119 - 120ms/epoch - 120ms/step\n",
      "Epoch 82/300\n",
      "1/1 - 0s - loss: 0.0115 - 131ms/epoch - 131ms/step\n",
      "Epoch 83/300\n",
      "1/1 - 0s - loss: 0.0123 - 135ms/epoch - 135ms/step\n",
      "Epoch 84/300\n",
      "1/1 - 0s - loss: 0.0130 - 121ms/epoch - 121ms/step\n",
      "Epoch 85/300\n",
      "1/1 - 0s - loss: 0.0114 - 114ms/epoch - 114ms/step\n",
      "Epoch 86/300\n",
      "1/1 - 0s - loss: 0.0113 - 123ms/epoch - 123ms/step\n",
      "Epoch 87/300\n",
      "1/1 - 0s - loss: 0.0122 - 131ms/epoch - 131ms/step\n",
      "Epoch 88/300\n",
      "1/1 - 0s - loss: 0.0116 - 116ms/epoch - 116ms/step\n",
      "Epoch 89/300\n",
      "1/1 - 0s - loss: 0.0117 - 115ms/epoch - 115ms/step\n",
      "Epoch 90/300\n",
      "1/1 - 0s - loss: 0.0112 - 111ms/epoch - 111ms/step\n",
      "Epoch 91/300\n",
      "1/1 - 0s - loss: 0.0101 - 132ms/epoch - 132ms/step\n",
      "Epoch 92/300\n",
      "1/1 - 0s - loss: 0.0118 - 159ms/epoch - 159ms/step\n",
      "Epoch 93/300\n",
      "1/1 - 0s - loss: 0.0112 - 136ms/epoch - 136ms/step\n",
      "Epoch 94/300\n",
      "1/1 - 0s - loss: 0.0111 - 118ms/epoch - 118ms/step\n",
      "Epoch 95/300\n",
      "1/1 - 0s - loss: 0.0108 - 115ms/epoch - 115ms/step\n",
      "Epoch 96/300\n",
      "1/1 - 0s - loss: 0.0123 - 132ms/epoch - 132ms/step\n",
      "Epoch 97/300\n",
      "1/1 - 0s - loss: 0.0117 - 129ms/epoch - 129ms/step\n",
      "Epoch 98/300\n",
      "1/1 - 0s - loss: 0.0108 - 115ms/epoch - 115ms/step\n",
      "Epoch 99/300\n",
      "1/1 - 0s - loss: 0.0121 - 111ms/epoch - 111ms/step\n",
      "Epoch 100/300\n",
      "1/1 - 0s - loss: 0.0110 - 148ms/epoch - 148ms/step\n",
      "Epoch 101/300\n",
      "1/1 - 0s - loss: 0.0114 - 130ms/epoch - 130ms/step\n",
      "Epoch 102/300\n",
      "1/1 - 0s - loss: 0.0118 - 125ms/epoch - 125ms/step\n",
      "Epoch 103/300\n",
      "1/1 - 0s - loss: 0.0113 - 116ms/epoch - 116ms/step\n",
      "Epoch 104/300\n",
      "1/1 - 0s - loss: 0.0123 - 113ms/epoch - 113ms/step\n",
      "Epoch 105/300\n",
      "1/1 - 0s - loss: 0.0111 - 120ms/epoch - 120ms/step\n",
      "Epoch 106/300\n",
      "1/1 - 0s - loss: 0.0117 - 128ms/epoch - 128ms/step\n",
      "Epoch 107/300\n",
      "1/1 - 0s - loss: 0.0119 - 120ms/epoch - 120ms/step\n",
      "Epoch 108/300\n",
      "1/1 - 0s - loss: 0.0113 - 123ms/epoch - 123ms/step\n",
      "Epoch 109/300\n",
      "1/1 - 0s - loss: 0.0126 - 105ms/epoch - 105ms/step\n",
      "Epoch 110/300\n",
      "1/1 - 0s - loss: 0.0103 - 130ms/epoch - 130ms/step\n",
      "Epoch 111/300\n",
      "1/1 - 0s - loss: 0.0119 - 133ms/epoch - 133ms/step\n",
      "Epoch 112/300\n",
      "1/1 - 0s - loss: 0.0105 - 117ms/epoch - 117ms/step\n",
      "Epoch 113/300\n",
      "1/1 - 0s - loss: 0.0105 - 111ms/epoch - 111ms/step\n",
      "Epoch 114/300\n",
      "1/1 - 0s - loss: 0.0113 - 111ms/epoch - 111ms/step\n",
      "Epoch 115/300\n",
      "1/1 - 0s - loss: 0.0119 - 122ms/epoch - 122ms/step\n",
      "Epoch 116/300\n",
      "1/1 - 0s - loss: 0.0100 - 131ms/epoch - 131ms/step\n",
      "Epoch 117/300\n",
      "1/1 - 0s - loss: 0.0108 - 127ms/epoch - 127ms/step\n",
      "Epoch 118/300\n",
      "1/1 - 0s - loss: 0.0119 - 207ms/epoch - 207ms/step\n",
      "Epoch 119/300\n",
      "1/1 - 0s - loss: 0.0110 - 135ms/epoch - 135ms/step\n",
      "Epoch 120/300\n",
      "1/1 - 0s - loss: 0.0111 - 134ms/epoch - 134ms/step\n",
      "Epoch 121/300\n",
      "1/1 - 0s - loss: 0.0115 - 120ms/epoch - 120ms/step\n",
      "Epoch 122/300\n",
      "1/1 - 0s - loss: 0.0098 - 117ms/epoch - 117ms/step\n",
      "Epoch 123/300\n",
      "1/1 - 0s - loss: 0.0106 - 108ms/epoch - 108ms/step\n",
      "Epoch 124/300\n",
      "1/1 - 0s - loss: 0.0108 - 123ms/epoch - 123ms/step\n",
      "Epoch 125/300\n",
      "1/1 - 0s - loss: 0.0111 - 134ms/epoch - 134ms/step\n",
      "Epoch 126/300\n",
      "1/1 - 0s - loss: 0.0099 - 136ms/epoch - 136ms/step\n",
      "Epoch 127/300\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(input_shape=(X_train.shape[1:]),units = 128,return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(128,return_sequences=False),\n",
    "    Dropout(0.25),\n",
    "    Dense(units=1),\n",
    "    Activation('linear')\n",
    "    \n",
    "])\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val)\n",
    "diff = []\n",
    "for i in range(len(y_val)):\n",
    "    pred = preds_val[i][0]\n",
    "    diff.append(y_val[i] - pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_min = preprocessor.data_min_[104]\n",
    "real_max = preprocessor.data_max_[104]\n",
    "print(preprocessor.data_min_[104])\n",
    "print(preprocessor.data_max_[104])\n",
    "\n",
    "preds_real = preds_val * (real_max - real_min) + real_min\n",
    "y_val_real = y_val * (real_max - real_min) + real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_real, label='Predictions')\n",
    "plt.plot(y_val_real, label='Actual values')\n",
    "plt.xlabel('test')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
